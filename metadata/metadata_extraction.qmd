---
title: "Metedata extraction"
format: html
editor: visual
---

```{r setup}

library(tidyverse)

```

https://www.ebi.ac.uk/ena/browser/search

# Vilgalys et al. 2022

-   Sequenced for this study: 430 Papio

```{r}

Vilgalys_Fogel <- read_tsv('PRJNA755322_Vilgalys_Fogel_2022.txt') 

Vilgalys_Fogel |> 
  group_by(scientific_name, sample_alias) |> 
  summarise(
    n = n()) |> 
  group_by(scientific_name) |> 
  summarise(
    n = n())

Vilgalys_Fogel |> 
  write_tsv("sample_names_vilgalys_fogel_2022.tsv")

```

All of the samples are found.

# SÃ¸rensen et al. 2023

-   Sequenced for the study: 217 Papio + 1 Gelada
-   Additional sequences from Rogers et al. 2019: 8 Papio + 1 Gelada

```{r}

Kuderna <- read_tsv('PRJEB59576_Kuderna_2023.txt') |> 
  filter(str_detect(scientific_name, 'Papio') | str_detect(scientific_name, 'gelada')) 

Kuderna |> 
  arrange(run_accession) 
  

Kuderna |> 
  group_by(scientific_name, sample_alias) |> 
  summarise(
    n = n()) |> 
  group_by(scientific_name) |> 
  summarise(
    n = n())


Kuderna |> 
  write_tsv("sample_names_kuderna_2023.tsv")

```

The following 48 IDs were missing, but are found in the latest pull from ENA:

```{r}

kuderna_missing <-str_split("PD_0492, PD_0493, PD_0494, PD_0495, PD_0496, PD_0497, PD_0498, PD_0499, PD_0500, PD_0501, PD_0502, PD_0503, PD_0504, PD_0505, PD_0506, PD_0507, PD_0508, PD_0509, PD_0637, PD_0641, PD_0642, PD_0649, PD_0650, PD_0651, PD_0652, PD_0653, PD_0654, PD_0658, PD_0659, PD_0662, PD_0674, PD_0675, PD_0676, PD_0677, PD_0678, PD_0679, PD_0680, PD_0681, PD_0682, PD_0683, PD_0684, PD_0685, PD_0686, PD_0687, PD_0688, PD_0689, PD_0690, PD_0691", ', ') |> unlist()

```

# Robinson et al. 2019

The following 100 IDs where retrieved from Table S2:

```{r}

whole_lst <- str_split("1_3548 FR07886417 1X0102 FR07921249 1X0110 FR07921242 1X1734 FR07921233 1X2049 FR07921237 1X2208 FR07886421 1X2304 FR07921251 1X3576 FR07921203 1_1979 FR07921245 1X0014 FR07886416 1X0026 FR07921246 1X0035 FR07886425 1X0153 FR07886426 1X0576 FR07886409 1X0580 FR07886405 1X0808 FR07921241 1X0812 FR07886420 1X0832 FR07921221 1X0951 FR07886413 1X1032 FR07921215 1X1125 FR07921272 1X1126 FR07921226 1X1146 FR07921240 1X1152 FR07886411 1X1181 FR07921270 1X1672 FR07921258 1X1700 FR07921265 1X1765 FR07921266 1X1939 FR07921262 1X1947 FR07921235 1X2891 FR07919467 1X3162 FR07921212 1X4384 FR07921206 6716 FR07918883 7091 FR07886418 7158 FR07886424 7937 FR07937957 8170 FR07918874 8344 FR07886410 8465 FR07886414 8653 FR07886404 8780 FR07918882 9562 FR07918881 9656 FR07937989", ' ') |> 
  unlist() 

lst <- whole_lst[!str_detect(whole_lst, '^FR')] 

lst <- c(lst, str_split("9841, 9860, 10173, 10192, 10349, 10488, 11887, 12242, 13245, 13644, 14022, 14182, 14276, 14460, 14652, 14712, 14925, 14930, 14959, 15009, 15107, 15150, 15156, 15190, 15197, 15421", ', ') |> unlist())

lst <- c(lst, str_split("15444, 15467, 15626, 15628, 15633, 16413, 16517, 17199, 18385, 18929, 19207, 25347, 19181, 19348, 26196, 26988, 27351", ', ') |> unlist())

lst <- c(lst, str_split("28246, 28279, 28635, 1X2231, 1X2816, 1X3697, 1X3796, 1X3822, 1X3837, 1X4179, 1X4209, 1X4777, 1X4853", ', ') |> unlist())

lst

```

```{r}

Robinson <- read_tsv('PRJNA433868_Robinson_2019.txt') 

Robinson |> 
  group_by(scientific_name, sample_alias, sample_accession) |> 
  summarise(
    n = n()) |> 
  group_by(scientific_name) |> 
  summarise(
    n = n())
  

Robinson |> 
  write_tsv("sample_names_robinson_2019.tsv")

```

```{r}

shuyu_list <- c("SAMN10524564", "SAMN10524546", "SAMN10524552", "SAMN10524565", "SAMN10524554", "SAMN10524539", "SAMN10524543", "SAMN10524555", "SAMN10524547", "SAMN10524550", "SAMN10524563", "SAMN10524560", "SAMN10524551", "SAMN10524559", "SAMN11119509", "SAMN10524549", "SAMN10524562", "SAMN10524548", "SAMN11119508", "SAMN10524566", "SAMN11119507", "SAMN10524544", "SAMN09761236", "SAMN10524567", "SAMN10524561", "SAMN10524540", "SAMN10524545", "SAMN10524541", "SAMN10524556", "SAMN10524558", "SAMN10524542")

paste0(filter(Robinson, sample_accession %in% shuyu_list)$run_accession, collapse = "\\|") |> 
  cat()

shuyu_list %in% Robinson$sample_accession


```

All of the samples are found.

6 of the samples have two sample_accessions. The larger set of numbers corresponds to an unpublished resequencing effort. thus, we will filter out those samples

```{r}

only_100 <- Robinson |> 
  group_by(sample_alias, sample_accession) |> 
  summarise(
    n = n()
    ) |> 
  ungroup() |> 
  filter(sample_alias %in% lst) 

repeated <- only_100 |> 
  group_by(sample_alias) |> 
  filter(n() > 1) |> 
  mutate(
    founder = sample_accession %in% shuyu_list
  ) |> 
  arrange(sample_accession)

paste(only_100$sample_accession[!(only_100$sample_accession %in% repeated$sample_accession[7:12])], collapse = "', '")

```
According to Gencove, these have large duplication rates:

```{r}

only_100 |> 
  filter(sample_alias %in% c("17199", "19181"))

```



```{r}

Robinson |> 
  group_by(sample_alias, sample_accession) |> 
  sample_n(1) |> 
  ungroup() |> 
  select(sample_alias, sample_accession) |> 
  write_csv('robinson_sampleAlias_to_sampleAccession.csv')

```






# Rogers et al. 2019

Each Papio species has a separate project identifier. The following file contains the metadata merged for the following projects: - Theropithecus gelada: PRJNA251424 - Papio kindae: PRJNA162517 - Papio ursinus: PRJNA54009 - Papio cynocephalus: PRJNA54007 - Papio anubis: PRJNA54005 - Papio papio: PRJNA54003 - Papio hamadryas: PRJNA20425

```{r}

`%+%` <- function(x, y) {bind_rows(x, y)}

cols_baboons <- cols(
  study_accession = col_character(),
  sample_accession = col_character(),
  experiment_accession = col_character(),
  run_accession = col_character(),
  tax_id = col_double(),
  scientific_name = col_character(),
  fastq_ftp = col_character(),
  sample_alias = col_character()
)

Rogers <- read_tsv('PRJNA251424_Rogers_2019_Theropithecus_gelada.txt', col_types = cols_baboons) %+%
  read_tsv('PRJNA162517_Rogers_2019_Papio_kindae.txt', col_types = cols_baboons) %+%
  read_tsv('PRJNA54009_Rogers_2019_Papio_urisnus.txt', col_types = cols_baboons) %+%
  read_tsv('PRJNA54007_Rogers_2019_Papio_cynocephalus.txt', col_types = cols_baboons) %+%
  read_tsv('PRJNA54005_Rogers_2019_Papio_anubis.txt', col_types = cols_baboons) %+%
  read_tsv('PRJNA54003_Rogers_2019_Papio_papio.txt', col_types = cols_baboons) %+%
  read_tsv('PRJNA20425_Rogers_2019_Papio_hamadryas.txt', col_types = cols_baboons) |> 
  filter(
    sample_alias != 'SAMN02981400'
  )

Rogers |> 
  group_by(scientific_name, sample_alias) |> 
  summarise(
    n = n()
    ) 

Rogers |> 
  group_by(scientific_name, sample_alias) |> 
  summarise(
    n = n()
    ) |> 
  group_by(scientific_name) |> 
  summarise(
    n = n()
    ) 

# Rogers |> 
#   filter(str_detect(fastq_md5, ';'))|> 
#   group_by(scientific_name, sample_alias) |> 
#   summarise(
#     n = n()
#     ) 

Rogers |> 
  write_tsv("sample_names_rogers_2019.tsv")


```

# Snyder-Mackler et al. 2016

Some of these samples were not used. The following IDs were retrieved from Table S2:

```{r}

amb_lst <- str_split("AMB_001, AMB_002, AMB_003, AMB_004, AMB_005, AMB_006, AMB_007, AMB_008, AMB_009, AMB_010, AMB_011, AMB_012, AMB_013, AMB_014, AMB_015, AMB_016, AMB_017, AMB_018, AMB_019, AMB_020, AMB_021, AMB_022, AMB_023, AMB_024, AMB_025, AMB_026, AMB_027, AMB_028, AMB_029, AMB_030, AMB_031, AMB_032, AMB_033, AMB_034, AMB_035, AMB_036, AMB_037, AMB_038, AMB_039, AMB_040, AMB_041, AMB_042, AMB_043, AMB_044, AMB_045, AMB_046, AMB_047, AMB_048, AMB_049, AMB_050, AMB_051, AMB_052, GK_003, GK_004, GK_005, GK_008, GK_009, GK_010, GK_011, GK_012", ', ') |> unlist()

amb_lst <- c(amb_lst, c('LIT_fDNA', 'LIT_gDNA', 'HAP_fDNA', 'HAP_gDNA'))

```

`LIT` and `HAP` are two samples for which there is both fecal and blood-derived genomic data.

```{r}

Snyder_Mackler <- read_tsv('PRJNA295782_Snyder-Mackler_2016.txt') 

Snyder_Mackler |>
  group_by(sample_alias) |> 
  summarise(
    n = n()
    ) |> 
  filter(sample_alias %in% amb_lst)

Snyder_Mackler |> 
  group_by(scientific_name, sample_alias) |> 
  summarise(
    n = n()) |> 
  group_by(scientific_name) |> 
  summarise(
    n = n())

Snyder_Mackler |> 
  write_tsv("sample_names_snyder-mackler_2016.tsv")

```


# Wall et al. 2016

-   New genome assembly for yellow baboon
-   Low-coverage resequencing for 44 baboons (yellow, anubis and mixed)

```{r}

Wall <- read_tsv('PRJNA308870_Wall_2016.txt') |> 
  filter(
    sample_alias != 'Pcyn_1.0'
  )

Wall |>
  group_by(scientific_name, sample_alias) |> 
  summarise(
    n = n()
    ) 

Wall |>
  group_by(scientific_name, sample_alias) |> 
  summarise(
    n = n()
    ) |> 
  group_by(scientific_name) |> 
  summarise(
    n = n()
    ) 

Wall |> 
  write_tsv("sample_names_wall_2016.tsv")

```

# Saving files

```{r}

total <- Vilgalys_Fogel %+% 
  Kuderna %+% 
  Rogers %+% 
  Robinson %+% 
  Snyder_Mackler %+% 
  Wall

save_lst <- function(data) {
  str_split(data$fastq_ftp, ';') |> unlist() |> write_lines(paste0(deparse(substitute(data)), '.txt'))
}

save_lst(Kuderna)
save_lst(Rogers)
save_lst(Robinson)
save_lst(Snyder_Mackler)
save_lst(Wall)
save_lst(Vilgalys_Fogel)



```

```{r}

save_md5sums <- function(data, prefix) {
  dat <- tibble(
    fastq_md5 = str_split(data$fastq_md5, ';') |> unlist(),
    file = paste0(prefix, unlist(str_split(data$fastq_ftp, ';')) |> lapply(function(x){unlist(str_split(x, '/'))[length(unlist(str_split(x, '/')))]}) |> unlist())
  )
  dat |> write_delim(paste0(str_remove(prefix, '/'), '.md5'), delim = ' ', col_names = FALSE)
}

save_md5sums(Kuderna, 'kuderna_2023/') 
save_md5sums(Robinson, 'robinson_2019/')
save_md5sums(Rogers, 'rogers_2019/')
save_md5sums(Snyder_Mackler, 'snyder-mackler_2016/')
save_md5sums(Wall, 'wall_2016/')
save_md5sums(Vilgalys_Fogel, 'vilgalys_fogel_2022/')

read_delim('kuderna_2023.md5', delim = ' ', col_names = F) |> 
  bind_rows(read_delim('robinson_2019.md5', delim = ' ', col_names = F)) |>
  bind_rows(read_delim('rogers_2019.md5', delim = ' ', col_names = F)) |> 
  bind_rows(read_delim('snyder-mackler_2016.md5', delim = ' ', col_names = F)) |> 
  bind_rows(read_delim('wall_2016.md5', delim = ' ', col_names = F)) |> 
  bind_rows(read_delim('vilgalys_fogel_2022.md5', delim = ' ', col_names = F)) |> 
  write_delim('myfiles_new.md5', delim = ' ', col_names = FALSE)

```

# Mapping Amboseli names

```{r}

# Load tables from Babase
vil <- read_csv("metadata_from_babase_vilgalys2022.csv") |> 
  transmute(
    id_vil = table_s1_id,
    sname
  ) 
sny <- read_csv("metadata_from_babase_snydermackler2016.csv") |> 
  transmute(
    id_sny = ncbi_id,
    sname
  ) |> 
  distinct()
wal <- read_csv("metadata_from_babase_wall2016.csv") |> 
  filter(source == 'Amboseli') |> 
  transmute(
    id_wal = library_name,
    ncbi_id,
    sname = str_sub(id, 1, 3)
  )


read_csv("metadata_from_babase_snydermackler2016.csv") |> 
  group_by(sname) |> 
  filter(length(unique(ncbi_id)) > 1) |> 
  ungroup() |> 
  arrange(sname)

```

```{r}

meta_vil <- Vilgalys_Fogel |> 
  group_by(sample_alias, sample_accession) |> 
  summarise(n = n()) |> 
  ungroup() |> 
  select(-n) |> 
  left_join(vil, by = join_by(sample_alias == id_vil)) |> 
  mutate(study = "vil")
  
meta_sny <- Snyder_Mackler |> 
  group_by(sample_alias) |> 
  summarise(sample_accession = paste(run_accession, collapse = ";"), n = n()) |> 
  ungroup() |> 
  select(-n) |> 
  left_join(sny, by = join_by(sample_alias == id_sny)) |> 
  mutate(
    sname = ifelse(sample_alias %in% c('HAP_fDNA', "HAP_gDNA"),
                   "HAP",
                   sname),
    sname = ifelse(sample_alias %in% c('LIT_fDNA', "LIT_gDNA"),
                   "LIT",
                   sname)
  ) |> 
  mutate(study = "sny")

meta_wal <- Wall |> 
  group_by(sample_alias, run_accession) |> 
  summarise(n = n()) |> 
  ungroup() |> 
  select(-n, sample_accession = run_accession) |> 
  left_join(wal, by = join_by(sample_alias == id_wal)) |> 
  transmute(sample_alias = ncbi_id, sample_accession, sname) |> 
  mutate(study = "wal")


arielle_vfc_gencove <- read_delim("fastqs_metadata_for_Gencove_8Jul2022.csv", ";")

final_table <- arielle_vfc_gencove |> 
  mutate(
    Accession = str_remove_all(Accession, " ")
  ) |> 
  left_join(
    bind_rows(meta_sny, meta_vil, meta_wal),
    by = join_by(Accession == sample_accession)
    ) 

final_table |> 
  write_csv('fastqs_metadata_for_Gencove_8Jul2022_with_snames.csv')

```

```{r}

final_table |> 
  group_by(id) |> 
  mutate(n = n()) |> 
  ungroup() |> 
  filter(n > 1) |> 
  arrange(id) |> 
  select(id, Study, sname) |> 
  write_csv("duplicate_samples_gencove_metadata.csv")

```


# Selecting sequences for poop

```{r}

amboseli_imputed_vcf <- c("LQF-AMB-014", "LQF-AMB-015", "LQF-AMB-082", "LQF-AMB-105", "LQF-AMB-106", "LQF-AMB-107", "LQF-AMB-111", "LQF-AMB-114", "LQF-AMB-184", "LQF-AMB-239", "LQF-AMB-254", "LQF-AMB-255", "LQF-AMB-257", "LQF-AMB-258", "LQF-AMB-261", "LQF-AMB-272", "LQF-AMB-274", "LQF-AMB-282", "LQF-AMB-293", "LQF-AMB-311", "LQF-AMB-317", "LQF-AMB-446", "LQF-AMB-448", "LQF-AMB-449", "LQF-AMB-452", "LQF-AMB-453", "LQF-AMB-454", "LQF-AMB-455", "LQF-AMB-456", "LQF-AMB-457", "LQF-AMB-458", "LQF-AMB-459", "LQF-AMB-460", "LQF-AMB-461", "LQF-AMB-462", "LQF-AMB-463") |> 
  str_remove_all('LQF-') |> 
  str_replace_all("-", "_") |> 
  sort()

amboseli_imputed_vcf 

```



```{r}

# Previously published, low-quality fecal

## 52, including HAP_fDNA and LIT_fDNA. AMB_041 and AMB_043 are missing.
only_fecal <-
  final_table |>
  filter(population == "Amboseli", sample_type == "low_quality_fecal") |>
  mutate(
    imputed = id %in% amboseli_imputed_vcf
  ) |>
  select(sample_alias, imputed)

## 52, all labeled as AMB_XXX. There are no stats about HAP_fDNA and LIT_fDNA.
fec <- read_csv('TableS2_Snyder-Mackler.csv') |> 
  transmute(
    id = library_name,
    endogenous_percentage = as.numeric(str_remove_all(`% baboon DNA pre-enrichment`, '%'))
  ) |> 
  left_join(sny, by = join_by(id == id_sny)) |> 
  left_join(only_fecal, by = join_by(id == sample_alias)) |> 
  select(-id)
  

# Previously published, high-quality tissue

only_tissue <- final_table |> 
  filter(population == "Amboseli", sample_type == "high_quality_tissue") |> 
  select(id, sname)

prev <- read_csv('TableS1_Vilgalys_Fogel.csv') |> 
  filter(population == "Amboseli") |> 
  transmute(
    id, 
    population,
    coverage = nodup_mapq10_coveraged
  ) |> 
  full_join(only_tissue, by = join_by(id)) |> 
  select(sname, coverage) |> 
  arrange(desc(is.na(sname))) |> 
  mutate(
    type = "prev",
    sname = ifelse(is.na(sname), paste0("UNK_", 1:n()), sname)
  ) 


# Newly generated, high-quality tissue

new <- read_csv('newly_sequenced_baboons_coverage.csv') |> 
  transmute(
    sname, 
    coverage = round(total_bp/(2.9*(10^9)), 3),
    type = 'new'
  )

# Combine

total_table <- bind_rows(prev, new) |> 
  group_by(sname) |> 
  summarise(
    gDNA_coverage = sum(coverage),
    n = n(),
    tag = paste0(type, collapse = ",")
  ) |> 
  left_join(fec, by = "sname") 

total_table  |> 
  select(-tag) |> 
  write_csv('Amboseli_gDNA_fDNA_stats_20240319.csv')

total_table |> 
  group_by(n) |> 
  tally()

sum(new$sname %in% prev$sname)

read_csv('newly_sequenced_baboons_coverage.csv') |> 
  filter(sname == "WAJ")

total_table |> 
  filter(tag == "new")

```











